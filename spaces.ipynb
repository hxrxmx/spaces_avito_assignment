{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b040a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (21.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: razdel in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy pyarrow tqdm lxml razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5c2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import tokenize\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "9d0aaccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57755fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset_1937770_3.txt\", \"r\", encoding=\"utf8\") as in_file:\n",
    "    with open(\"dataset.txt\", \"w\", encoding=\"utf8\") as out_file:\n",
    "        for line in in_file.readlines():\n",
    "            out_file.write(line.replace(\",\", \";\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4237808b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20                 –∏—â—É–ø–æ–¥—Ä–∞–±–æ—Ç–∫—É–ø–æ–≤–µ—á–µ—Ä–∞–º\n",
       "71                   –∏—â—É—Ä–∞–±–æ—Ç—É–æ—Ñ–∏—Ü–∏–∞–Ω—Ç–∫–æ–π\n",
       "102          –∫—É–ø–ª—é–∫–æ–≤—Ä–∏–∫–¥–ª—è–π–æ–≥–∏,–Ω–µ–¥–æ—Ä–æ–≥–æ!\n",
       "106    –∏—â—É–¥—Ä—É–∑–µ–π–¥–ª—è–ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–π,–ª–µ—Ç–æ–º–≤–≥–æ—Ä—ã\n",
       "121         –∏—â—É—Å—Ç–æ–ª–∏–∫–¥–ª—è–Ω–æ—É—Ç–±—É–∫–∞,—Å–∫–ª–∞–¥–Ω–æ–π\n",
       "270                     –∫—É–ø–ª—é–≥–∏—Ç–∞—Ä—ÉGibson\n",
       "435               –ö–æ–≥–¥–∞–Ω–∞—á–∞—Å–∞—Ö–≤–∞–∂–Ω—ã–º–∏–Ω—É—Ç—ã\n",
       "614                       –í–µ—Ä—Ö–æ–º–Ω–∞–∑–≤–µ–∑–¥–µ,\n",
       "700                     –ñ–¥—É—Ç–µ–≥–æ–¥–æ–º–∞–≤—Å–µ–≥–¥–∞\n",
       "860      –Ø–Ω–∏–≤—á–µ–º–Ω–µ–æ—Ç–∫–∞–∂—É,—è–Ω–∏–≤—á—ë–º–Ω–µ–æ—Ç–∫–∞–∂—É!\n",
       "Name: text_no_spaces, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset.txt\", sep=\";\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "\n",
    "random_idxs = np.random.randint(0, 1000, 10)\n",
    "\n",
    "data[\"text_no_spaces\"][np.isin(data[\"id\"], random_idxs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba50b6be",
   "metadata": {},
   "source": [
    "–í–æ –≤—Ä–µ–º—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–±–æ–≤–∞–ª—Å—è –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–∑–¥–µ–ª—è–µ—Ç –ø–æ —Å–º—ã—Å–ª–æ–≤—ã–º –µ–¥–∏–Ω–∏—Ü–∞–º, –∞ –Ω–µ –ø—Ä–æ–±–µ–ª–∞–º –∏ —Å–∏–º–≤–æ–ª–∞–º, –Ω–æ –Ω–∞ —Å—ã—Ä–æ–º —Ç–µ–∫—Å—Ç–µ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –æ–Ω –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–µ–±—è –Ω–µ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ. –í —Å–≤—è–∑–∏ —Å —ç—Ç–∏–º, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π, –ø–æ —Å—É—Ç–∏, –ø–æ–ª–µ–∑–µ–Ω —Ç–æ–ª—å–∫–æ —á—Ç–æ–± –æ—Ç–¥–µ–ª—è—Ç—å —Å–∏–º–≤–æ–ª—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793ad3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–∫—É–ø–ª—é–∫–æ–≤—Ä–∏–∫–¥–ª—è–π–æ–≥–∏', ',', '–Ω–µ–¥–æ—Ä–æ–≥–æ', '!']\n",
      "['–ö–æ–≥–¥–∞–Ω–∞—á–∞—Å–∞—Ö–≤–∞–∂–Ω—ã–º–∏–Ω—É—Ç—ã']\n",
      "['–Ø–Ω–∏–≤—á–µ–º–Ω–µ–æ—Ç–∫–∞–∂—É', ',', '—è–Ω–∏–≤—á—ë–º–Ω–µ–æ—Ç–∫–∞–∂—É', '!']\n",
      "['–∫—É–ø–ª—é–≥–∏—Ç–∞—Ä—É', 'Gibson']\n",
      "['–∏—â—É–¥—Ä—É–∑–µ–π–¥–ª—è–ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–π', ',', '–ª–µ—Ç–æ–º–≤–≥–æ—Ä—ã']\n",
      "['–∏—â—É—Ä–∞–±–æ—Ç—É–æ—Ñ–∏—Ü–∏–∞–Ω—Ç–∫–æ–π']\n",
      "['–ñ–¥—É—Ç–µ–≥–æ–¥–æ–º–∞–≤—Å–µ–≥–¥–∞']\n",
      "['–∏—â—É–ø–æ–¥—Ä–∞–±–æ—Ç–∫—É–ø–æ–≤–µ—á–µ—Ä–∞–º']\n",
      "['–í–µ—Ä—Ö–æ–º–Ω–∞–∑–≤–µ–∑–¥–µ', ',']\n",
      "['–∏—â—É—Å—Ç–æ–ª–∏–∫–¥–ª—è–Ω–æ—É—Ç–±—É–∫–∞', ',', '—Å–∫–ª–∞–¥–Ω–æ–π']\n"
     ]
    }
   ],
   "source": [
    "corpus = data[\"text_no_spaces\"]\n",
    "\n",
    "for text in corpus[random_idxs]:\n",
    "\ttokens = [token.text for token in tokenize(text)]\n",
    "\tprint(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3603a0",
   "metadata": {},
   "source": [
    "–¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä–æ–º –Ω–∞ –≥–ª–∞–∑ –≤–∏–¥–Ω–æ, —á—Ç–æ —Ç–µ–∫—Å—Ç—ã –¥–µ–ª—è—Ç—Å—è –æ—á–µ–Ω—å –ø–ª–æ—Ö–æ. –ö–∞–∂–µ—Ç—Å—è, –Ω–µ –∏–º–µ–µ—Ç –±–æ–ª—å—à–æ–≥–æ —Å–º—ã—Å–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π –ø–æ–¥—Ö–æ–¥. (–ø—Ä–∏—á–µ–º, –ª–∞–¥–Ω–æ –±—ã –æ–Ω –¥–µ–ª–∞–ª —Ç–æ–ª—å–∫–æ –ª–∏—à–Ω–∏–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è. –ú–æ–∂–Ω–æ –±—ã–ª–æ –±—ã —Ç–æ–≥–¥–∞ —Å–≤–µ—Å—Ç–∏ –∑–∞–¥–∞—á—É –∫ –ø–æ–ø—ã—Ç–∫–µ —Å–∫–ª–µ–∏—Ç—å –ª–∏—à–Ω–∏–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è. –ù–æ —Å —Ç–∞–∫–æ–π —Ä–∞–±–æ—Ç–æ–π, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è, –æ–Ω –∏ –ª–∏—à–Ω–∏—Ö —Ä–∞–∑–±–∏–µ–Ω–∏–π –º–Ω–æ–≥–æ —Å–¥–µ–ª–∞–ª, –∏ –Ω–µ –≤–µ–∑–¥–µ —Ç–∞–º, –≥–¥–µ –Ω–∞–¥–æ, —Ä–∞–∑–±–∏–ª)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e02137",
   "metadata": {},
   "source": [
    "–£ –Ω–∞—Å –µ—Å—Ç—å –∑–∞–¥–∞—á–∞: –ø–æ–¥–µ–ª–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±—ã–ª –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–º, –∞ –∑–Ω–∞—á–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–º —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ —Å–ª–æ–≤ –≤–º–µ—Å—Ç–µ.\n",
    "\n",
    "—Ç–æ –µ—Å—Ç—å, –ø—É—Å—Ç—å –µ—Å—Ç—å —Å—Ç—Ä–æ–∫–∞ \"–∫—É–ø–ª—é–∫–æ–≤—Ä–∏–∫\". –ú–æ–∂–Ω–æ –ø–æ–¥–µ–ª–∏—Ç—å –µ–µ –æ–≥—Ä–æ–º–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–ø–æ—Å–æ–±–æ–≤ –ø—Ä–æ–±–µ–ª–∞–º–∏. –ü—Ä–∏ —ç—Ç–æ–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ \"–∫—É–ø–ª—é –∫–æ–≤—Ä–∏–∫\" –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª–µ–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º, —á–µ–º –∫–∞–∫–æ–µ –±—ã —Ç–æ –Ω–∏ –±—ã–ª–æ –¥—Ä—É–≥–æ–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä \"–∫—É–ø –ª—é–∫–æ–≤ —Ä–∏–∫\". –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ—Å—Ç—å –æ—Ç—Ä–∞–∂–∞–µ—Ç—Å—è –±–æ–ª—å—à–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –≤—Å—Ç—Ä–µ—á–∏ —Å–ª–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π. –ü—É—Å—Ç—å —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ -- —ç—Ç–æ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª $x = \\{x_1, .., x_n\\}$. –¢–æ–≥–¥–∞ –∏—Å—Ç–∏–Ω–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ $x^* = \\{x_1^*, .., x_k^*\\}$ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–µ (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –Ω–µ –≤—Å–µ–≥–¥–∞ –∏ –º–æ–∂–Ω–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã, –Ω–æ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è):\n",
    "\n",
    "$$\n",
    "\tp(x^*) \\gtrsim p(x) \\quad \\forall x \\neq x^*,\n",
    "$$\n",
    "\n",
    "–≥–¥–µ\n",
    "$$\n",
    "\\begin{split}\n",
    "\tp(x^*) \\equiv p(x_1^*, ... , x_k^*) = p(x_1^*) \\cdot p(x_2^* | x_1^*) \\cdot ... \\cdot p(x_k^* | x_1^*, ... x_{k-1}^*), \\\\\n",
    "\tp(x) \\equiv p(x_1, ... , x_n) = .... \\text{–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –∑–Ω–∞—è –≤—Å–µ —É—Å–ª–æ–≤–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ —Å–ª–æ–≤–æ $y_1$ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥—Ä—É–≥–∏—Ö —Å–ª–æ–≤ $\\{y_i\\}_{i=2}^{m}$ –≤ —Ç–µ–∫—Å—Ç–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, –º–æ–∂–Ω–æ —Ä–∞–∑—Ä–µ—à–∏—Ç—å —ç—Ç—É –∑–∞–¥–∞—á—É.\n",
    "\n",
    "–ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∑–Ω–∞—Ç—å –≤—Å–µ —Ç–∞–∫–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ, –ø–æ—ç—Ç–æ–º—É –Ω—É–∂–Ω–æ –ø—Ä–∏–±–µ–≥–Ω—É—Ç—å –∫ –Ω–µ–∫–æ—Ç–æ—Ä—ã–º —É–ø—Ä–æ—â–µ–Ω–∏—è–º.\n",
    "\n",
    "–ü–µ—Ä–≤–æ–µ –¥–æ–ø—É—â–µ–Ω–∏–µ —Ç–∏–ø–∞ –º–∞—Ä–∫–æ–≤—Å–∫–æ–≥–æ. –°—á–∏—Ç–∞–µ–º, —á—Ç–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å–ª–æ–≤–∞ –∏–∑ –Ω–∞—á–∞–ª–∞ –Ω–µ —Å–∏–ª—å–Ω–æ –≤–ª–∏—è—é—Ç –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ª–æ–≤ —Å –∫–æ–Ω—Ü–∞, —Ç–æ –µ—Å—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ $l$ —Å–ª–æ–≤ –ø–µ—Ä–µ–¥ –∏—Å—Ö–æ–¥–Ω—ã–º —Å —Ö–æ—Ä–æ—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é —Ö–≤–∞—Ç–∏—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏, –ø–æ—Å–∫–æ–ª—å–∫—É $p(x_i | x_{i-1}, x_{i-2}, ... , x_{1}) \\approx p(x_i | \\underbrace{x_{i-1}, x_{i-2}, ... , x_{i-l}, x_{i-l - 1}}_{l})$\n",
    "\n",
    "–ù–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –¥–∞–∂–µ –ø–æ–¥—Ö–æ–¥ —Å $l=0$ (—É–Ω–∏–≥—Ä–∞–º–º—ã) –æ—Ç—Å–µ–∏—Ç –º–Ω–æ–≥–æ –º—É—Å–æ—Ä–∞, —Ç–∞–∫ –∫–∞–∫ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º —É—á–∞—Å—Ç–≤—É–µ—Ç —Å–ª–æ–≤–æ \"—Ä–∏–∫\" –∏–∑-–∑–∞ –æ–¥–Ω–æ–π —Ç–æ–ª—å–∫–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ $p(\"—Ä–∏–∫\") \\approx 0$ —Å–≤–µ–¥–µ—Ç –∫ –º–∞–ª–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é –∏–ª–∏ –Ω—É–ª—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—Å–µ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è $p(\"–∫—É–ø\", \"–ª—é–∫–æ–≤\", \"—Ä–∏–∫\") \\approx p(\"–∫—É–ø\") \\cdot p(\"–ª—é–∫–æ–≤\") \\cdot p(\"—Ä–∏–∫\") \\approx 0$. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∂–µ –ø—Ä–æ—Å—Ç–æ –∞–¥–µ–∫–≤–∞—Ç–Ω–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –±—É–¥–µ—Ç –±–æ–ª—å—à–µ —ç—Ç–æ–≥–æ.\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ, –±—ã–ª–æ –±—ã –∑–¥–æ—Ä–æ–≤–æ –∏–∑ –¥–≤—É—Ö –∞–¥–µ–∫–≤–∞—Ç–Ω—ã—Ö —Ä–∞–∑–±–∏–µ–Ω–∏–π (–∫–æ—Ç–æ—Ä—ã–µ, –≤–µ—Ä–æ—è—Ç–Ω–æ, –º–æ–≥—É—Ç –≤—Å–µ —Ç–∞–∫–∏ –≤—Å—Ç—Ä–µ—á–∞—Ç—å—Å—è) –≤—ã–±–∏—Ä–∞—Ç—å –±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –ø–æ —Å–º—ã—Å–ª—É –∏–º–µ–Ω–Ω–æ –∫ –∑–∞–ø—Ä–æ—Å–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00694fc8",
   "metadata": {},
   "source": [
    "–°–∞–º–æ–µ —Å–ª–æ–∂–Ω–æ–µ –≤ —ç—Ç–æ–º –≤—Å–µ–º -- –Ω–∞–π—Ç–∏ –æ—Ç–∫—Ä—ã—Ç—ã–π –¥–∞—Ç–∞—Å–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ –±—ã–ª –±—ã –ø–æ—Ö–æ–∂ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã, –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –æ–ø–∏—Å–∞–Ω–∏—è —Å–æ —Å–ª–æ–≤–∞–º–∏, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–º–∏ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–æ–º (\"–∞–π—Ñ–æ–Ω\" –∏–ª–∏ \"–æ–ø–ø–æ\") –∏ –ø–æ–¥–æ–±–Ω—ã–º–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d282f4",
   "metadata": {},
   "source": [
    "–í—Ä–æ–¥–µ —Ç–æ, —á—Ç–æ –Ω–∞–¥–æ: https://www.kaggle.com/datasets/antonoof/avito-data. –ù–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–∞–≤–¥–∞, —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –æ–ø–∏—Å–∞–Ω–∏—è –æ–±—ä—è–≤–ª–µ–Ω–∏–π, –Ω–æ —á—Ç–æ-—Ç–æ –ª—É—á—à–µ –≤—Ä—è–¥ –ª–∏ –ø–æ–ª—É—á–∏—Ç—å—Å—è –Ω–∞–π—Ç–∏. –¢–∞–∫–∂–µ —Å–∫–∞—á–∞–µ–º –∫–æ—Ä–ø—É—Å —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤: https://www.opencorpora.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a10acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install kagglehub[pandas-datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1cf99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "# from kagglehub import KaggleDatasetAdapter\n",
    "# from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efcdb24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"avito_data.csv\"\n",
    "\n",
    "# df = kagglehub.dataset_load(\n",
    "# \tKaggleDatasetAdapter.PANDAS,\n",
    "# \t\"antonoof/avito-data\",\n",
    "# \tfile_path,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be6a0c",
   "metadata": {},
   "source": [
    "*–ù–ï –†–ê–ë–û–¢–ê–ï–¢, –í–´–î–ê–ï–¢ SSLEOFError*\n",
    "\n",
    "*–ü–†–ò –ü–†–û–í–ï–†–û–ß–ù–û–ú –ó–ê–ü–£–°–ö–ï –°–ö–ê–ß–ê–ô–¢–ï –î–ê–¢–ê–°–ï–¢–´ –í–†–£–ß–ù–£–Æ –ò –ü–û–ú–ï–°–¢–ò–¢–ï –ê–†–•–ò–í–´ –†–Ø–î–û–ú –° –ù–û–£–¢–ë–£–ö–û–ú*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3ff278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2f10420",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = Path('archive.zip')\n",
    "extract_path = Path('avito_data')\n",
    "extract_path.mkdir(exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e28b31",
   "metadata": {},
   "source": [
    "–ù—É–∂–Ω–æ —Å–∏–ª—å–Ω–æ –ø–æ—Å—Ç–∞—Ä–∞—Ç—å—Å—è, —á—Ç–æ–± —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–ª–æ–≤–∞–º –≤ —Ç–∞–∫–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –±—ã–ª–∞ –ø–æ—Ö–æ–∂–∞ –Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ —Å–ª–æ–≤–∞—Ö —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –≤–µ–¥—å —Ç—É—Ç –Ω–∞–º–µ—Ä–µ–Ω–Ω–æ –ø—Ä–∏–≤–µ–¥–µ–Ω–æ –º–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏—Ö, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏—Ö –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å–ª–æ–≤–∞. –û–¥–Ω–∞–∫–æ, —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Ç–µ–∫—Å—Ç—ã, –ø–æ—Ö–æ–∂–∏–µ –ø–æ –∏–Ω–¥–µ–∫—Å—É –ñ–∞–∫–∫–∞—Ä–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä, –±—É–¥–µ—Ç –æ—á–µ–Ω—å –¥–æ–ª–≥–æ. –ü–æ—ç—Ç–æ–º—É, –≤ —Ç—Ä–µ–π–Ω–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ —É–¥–∞–ª–∏–º –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏–º–µ—Ä—ã, —É –∫–æ—Ç–æ—Ä—ã—Ö –¥—É–±–ª–∏—Ä—É–µ—Ç—Å—è id –∏ –ø—Ä–∏–º–µ—Ä—ã, –≥–¥–µ —Å—Ç–æ–∏—Ç —Ñ–ª–∞–≥ is_double, –∞ –≤ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ —É–¥–∞–ª–∏–º –ø—Ä–æ—Å—Ç–æ –≤—Å–µ—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd77ed37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:16<00:00,  4.02s/it]\n"
     ]
    }
   ],
   "source": [
    "train_files = list((extract_path / \"data\").glob(\"train_part_*.snappy.parquet\"))\n",
    "train_cols = ['base_item_id', 'cand_item_id', 'is_double', 'base_title', 'cand_title', 'base_description', 'cand_description']\n",
    "train_df = pd.concat([pd.read_parquet(f, columns=train_cols) for f in tqdm(train_files)], ignore_index=True)\n",
    "\n",
    "doubles_df = train_df[train_df['is_double'] == 1]\n",
    "blacklisted_ids = set(doubles_df['base_item_id']).union(set(doubles_df['cand_item_id']))\n",
    "\n",
    "base_train = train_df[['base_item_id', 'base_title', 'base_description']].rename(columns={'base_item_id': 'item_id', 'base_title': 'title', 'base_description': 'description'})\n",
    "cand_train = train_df[['cand_item_id', 'cand_title', 'cand_description']].rename(columns={'cand_item_id': 'item_id', 'cand_title': 'title', 'cand_description': 'description'})\n",
    "all_train_df = pd.concat([base_train, cand_train], ignore_index=True).drop_duplicates()\n",
    "\n",
    "cleaned_train_df = all_train_df[~all_train_df[\"item_id\"].isin(blacklisted_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deaf70ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "test_files = list((extract_path / \"data\").glob(\"test_part_*.snappy.parquet\"))\n",
    "test_cols = ['base_item_id', 'base_title', 'base_description']\n",
    "test_df = pd.concat([pd.read_parquet(f, columns=test_cols) for f in tqdm(test_files)], ignore_index=True)\n",
    "\n",
    "base_test = test_df.rename(columns={'base_item_id': 'item_id', 'base_title': 'title', 'base_description': 'description'})\n",
    "cleaned_test_df = base_test.drop_duplicates(subset=['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8b9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([cleaned_train_df, cleaned_test_df], ignore_index=True).drop_duplicates(subset=['item_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fbebfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>–ü–æ–¥–≥–æ–ª–æ–≤–Ω–∏–∫–∏ priora</td>\n",
       "      <td>–í —Ö–æp–æ—à–µ–º c–æc—Ç–æ—è–Ω–∏–∏ \\n–¶–µ–Ωa –∑a —à—Ç—É–∫—É\\n–üapa 900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>–ö–æc—Ç—é–º –¥–ª—è —Ça–Ω—Ü–µ–≤</td>\n",
       "      <td>–üp–æ–¥a—é –∫–æc—Ç—é–º –¥–ª—è —Ça–Ω—Ü–µ–≤ —Ñ–µ–µp–∏—è, –∑a–∫a–∑a–ª–∏ –Ωa –ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>–•–æ–∫–∫–µ–π–Ω—ã–µ —Çp—Éc—ã Easton Synergy 900 Sr L</td>\n",
       "      <td>üèí–•–æ–∫–∫–µ–π–Ω—ã–µ —Çp—Éc—ã Easton Synergy 900\\n\\nüî∏–†a–∑–º–µp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>–°—Ç—É–ª—å—á–∏–∫ –¥–ª—è –∫–æp–º–ª–µ–Ω–∏—è</td>\n",
       "      <td>c—Ç—É–ª—å—á–∏–∫ –≤ –æ—Ç–ª–∏—á–Ω–æ–º c–æc—Ç–æ—è–Ω–∏–∏. 3 –ø–æ–∑—ã, –º–æ–∂–Ω–æ –ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>–ë—éc—Ç–≥a–ª—å—Ç–µp Intimissimi –Ω–æ–≤—ã–π</td>\n",
       "      <td>–ù–æ–≤—ã–π –±—éc—Ç–≥a–ª—å—Ç–µp Intimissimi –º–æ–¥–µ–ª—å giada 80–ë...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>–õ—ã–∂–Ω—ã–µ –±–æ—Ç–∏–Ω–∫–∏ nordway 40</td>\n",
       "      <td>–üp–æ–¥a—é –ª—ã–∂–Ω—ã–µ –±–æ—Ç–∏–Ω–∫–∏ –≤ –∏–¥–µa–ª—å–Ω–æ–º c–æc—Ç–æ—è–Ω–∏–∏.–†a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>–üp–æ–∫–ªa–¥–∫–∏ –¥–ª—è –≥p—É–¥–∏</td>\n",
       "      <td>–í –æc—Ça—Ç–∫–µ 19 —à—Ç.–öa–∂–¥a—è –≤ –∏–Ω–¥–∏–≤–∏–¥—Éa–ª—å–Ω–æ–π —É–øa–∫–æ–≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>–°a–ª—Ñ–µ—Ç–∫a –¥–ª—è p—É–∫ –∏ –ª–∏—Üa –ºa—Öpa –≤—Ç –±–æp–¥–æ–≤—ã–π –ø–æ —Ü</td>\n",
       "      <td>–í–∏–¥ —Ç–æ–≤apa:  –°a–ª—Ñ–µ—Ç–∫a\\n–ùa–∑–Ωa—á–µ–Ω–∏–µ : –¥–ª—è p—É–∫ –∏ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>–óa–±–æp c–µ—Ç–∫a 3D</td>\n",
       "      <td>–óa–±–æp c–µ—Ç–∫a 3d\\n\\nüëç 3–¥ c–µ—Ç–∫a –≤ –Ωa–ª–∏—á–∏–∏ –∏ –ø–æ–¥ –∑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>–õ–µ–≥–æ –úa–π–Ω–∫pa—Ñ—Ç –î–µp–µ–≤–Ω—è 778 –¥–µ—Ça–ª–µ–π</td>\n",
       "      <td>–õ–µ–≥–æ –úa–π–Ω–∫pa—Ñ—Ç –î–µp–µ–≤–Ω—è 778 –¥–µ—Ça–ª–µ–π</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "20                              –ü–æ–¥–≥–æ–ª–æ–≤–Ω–∏–∫–∏ priora   \n",
       "71                                –ö–æc—Ç—é–º –¥–ª—è —Ça–Ω—Ü–µ–≤   \n",
       "102         –•–æ–∫–∫–µ–π–Ω—ã–µ —Çp—Éc—ã Easton Synergy 900 Sr L   \n",
       "106                          –°—Ç—É–ª—å—á–∏–∫ –¥–ª—è –∫–æp–º–ª–µ–Ω–∏—è   \n",
       "121                   –ë—éc—Ç–≥a–ª—å—Ç–µp Intimissimi –Ω–æ–≤—ã–π   \n",
       "270                       –õ—ã–∂–Ω—ã–µ –±–æ—Ç–∏–Ω–∫–∏ nordway 40   \n",
       "435                             –üp–æ–∫–ªa–¥–∫–∏ –¥–ª—è –≥p—É–¥–∏   \n",
       "614  –°a–ª—Ñ–µ—Ç–∫a –¥–ª—è p—É–∫ –∏ –ª–∏—Üa –ºa—Öpa –≤—Ç –±–æp–¥–æ–≤—ã–π –ø–æ —Ü   \n",
       "700                                  –óa–±–æp c–µ—Ç–∫a 3D   \n",
       "860              –õ–µ–≥–æ –úa–π–Ω–∫pa—Ñ—Ç –î–µp–µ–≤–Ω—è 778 –¥–µ—Ça–ª–µ–π   \n",
       "\n",
       "                                           description  \n",
       "20       –í —Ö–æp–æ—à–µ–º c–æc—Ç–æ—è–Ω–∏–∏ \\n–¶–µ–Ωa –∑a —à—Ç—É–∫—É\\n–üapa 900  \n",
       "71   –üp–æ–¥a—é –∫–æc—Ç—é–º –¥–ª—è —Ça–Ω—Ü–µ–≤ —Ñ–µ–µp–∏—è, –∑a–∫a–∑a–ª–∏ –Ωa –ø...  \n",
       "102  üèí–•–æ–∫–∫–µ–π–Ω—ã–µ —Çp—Éc—ã Easton Synergy 900\\n\\nüî∏–†a–∑–º–µp...  \n",
       "106  c—Ç—É–ª—å—á–∏–∫ –≤ –æ—Ç–ª–∏—á–Ω–æ–º c–æc—Ç–æ—è–Ω–∏–∏. 3 –ø–æ–∑—ã, –º–æ–∂–Ω–æ –ø...  \n",
       "121  –ù–æ–≤—ã–π –±—éc—Ç–≥a–ª—å—Ç–µp Intimissimi –º–æ–¥–µ–ª—å giada 80–ë...  \n",
       "270  –üp–æ–¥a—é –ª—ã–∂–Ω—ã–µ –±–æ—Ç–∏–Ω–∫–∏ –≤ –∏–¥–µa–ª—å–Ω–æ–º c–æc—Ç–æ—è–Ω–∏–∏.–†a...  \n",
       "435  –í –æc—Ça—Ç–∫–µ 19 —à—Ç.–öa–∂–¥a—è –≤ –∏–Ω–¥–∏–≤–∏–¥—Éa–ª—å–Ω–æ–π —É–øa–∫–æ–≤...  \n",
       "614  –í–∏–¥ —Ç–æ–≤apa:  –°a–ª—Ñ–µ—Ç–∫a\\n–ùa–∑–Ωa—á–µ–Ω–∏–µ : –¥–ª—è p—É–∫ –∏ ...  \n",
       "700  –óa–±–æp c–µ—Ç–∫a 3d\\n\\nüëç 3–¥ c–µ—Ç–∫a –≤ –Ωa–ª–∏—á–∏–∏ –∏ –ø–æ–¥ –∑...  \n",
       "860                 –õ–µ–≥–æ –úa–π–Ω–∫pa—Ñ—Ç –î–µp–µ–≤–Ω—è 778 –¥–µ—Ça–ª–µ–π  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[[\"title\", \"description\"]][np.isin(full_df.index, random_idxs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba390c45",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –Ω–∞–¥–æ —Å–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É, —É–¥–∞–ª–∏—Ç—å —Ö–æ—Ç—è –±—ã —É–∫–∞–∑–∞–Ω–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –ø—Ä–∏–≤–µ—Å—Ç–∏ –≤—Å–µ —Å–ª–æ–≤–∞ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "410a4daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2516491"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79df98",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ–π–¥–µ–º –∫–æ –≤—Ç–æ—Ä–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "900903de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2761b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = Path(\"annot.opcorpora.xml.zip\")\n",
    "extract_path = Path(\"open_corpora_data\")\n",
    "extract_path.mkdir(exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ff1fb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4007/4007 [00:00<00:00, 7164.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xml_corpus_0</td>\n",
       "      <td></td>\n",
       "      <td>\"–ß–∞—Å—Ç–Ω—ã–π –∫–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xml_corpus_1</td>\n",
       "      <td></td>\n",
       "      <td>00021 –®–∫–æ–ª–∞ –∑–ª–æ—Å–ª–æ–≤–∏—è ¬´–®–∫–æ–ª–∞ –∑–ª–æ—Å–ª–æ–≤–∏—è¬ª —É—á–∏—Ç –ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xml_corpus_2</td>\n",
       "      <td></td>\n",
       "      <td>00022 –ü–æ—Å–ª–µ–¥–Ω–µ–µ –≤–æ—Å—Å—Ç–∞–Ω–∏–µ –≤ –°–µ—É–ª–µ ¬´–ü–æ—Å–ª–µ–¥–Ω–µ–µ –≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xml_corpus_3</td>\n",
       "      <td></td>\n",
       "      <td>00023 –ó–∞ –∫–æ—Ç–∞ - –æ—Ç–≤–µ—Ç–∏—à—å! –ó–∞ –∫–æ—Ç–∞ ‚Äì –æ—Ç–≤–µ—Ç–∏—à—å! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xml_corpus_4</td>\n",
       "      <td></td>\n",
       "      <td>00024 –ë—ã—Å—Ç—Ä–æ—Ç–µ—á–Ω—ã–π –∫–∏–Ω–æ—Ä–æ–º–∞–Ω –ë—ã—Å—Ç—Ä–æ—Ç–µ—á–Ω—ã–π –∫–∏–Ω–æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>xml_corpus_4002</td>\n",
       "      <td></td>\n",
       "      <td>–ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –∏–ª–∏ –Ω—ë–±–Ω–∞—è...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>xml_corpus_4003</td>\n",
       "      <td></td>\n",
       "      <td>–ù–µ–±–æ –ù–µ–±–æ –ù–µ–±–æ (–ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –Ω–µ–±–µ—Å–∞, –Ω–µ–±–æ—Å–≤–æ–¥) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>xml_corpus_4004</td>\n",
       "      <td></td>\n",
       "      <td>–ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ ‚Äî —Å–æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>xml_corpus_4005</td>\n",
       "      <td></td>\n",
       "      <td>–î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ –Ω–µ–±–∞ –î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ –Ω...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>xml_corpus_4006</td>\n",
       "      <td></td>\n",
       "      <td>\" –ß–µ—Ä–Ω–æ–≤–∏–∫–∏</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4007 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              item_id title                                        description\n",
       "0        xml_corpus_0                                  \"–ß–∞—Å—Ç–Ω—ã–π –∫–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç\"\n",
       "1        xml_corpus_1        00021 –®–∫–æ–ª–∞ –∑–ª–æ—Å–ª–æ–≤–∏—è ¬´–®–∫–æ–ª–∞ –∑–ª–æ—Å–ª–æ–≤–∏—è¬ª —É—á–∏—Ç –ø...\n",
       "2        xml_corpus_2        00022 –ü–æ—Å–ª–µ–¥–Ω–µ–µ –≤–æ—Å—Å—Ç–∞–Ω–∏–µ –≤ –°–µ—É–ª–µ ¬´–ü–æ—Å–ª–µ–¥–Ω–µ–µ –≤...\n",
       "3        xml_corpus_3        00023 –ó–∞ –∫–æ—Ç–∞ - –æ—Ç–≤–µ—Ç–∏—à—å! –ó–∞ –∫–æ—Ç–∞ ‚Äì –æ—Ç–≤–µ—Ç–∏—à—å! ...\n",
       "4        xml_corpus_4        00024 –ë—ã—Å—Ç—Ä–æ—Ç–µ—á–Ω—ã–π –∫–∏–Ω–æ—Ä–æ–º–∞–Ω –ë—ã—Å—Ç—Ä–æ—Ç–µ—á–Ω—ã–π –∫–∏–Ω–æ...\n",
       "...               ...   ...                                                ...\n",
       "4002  xml_corpus_4002        –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –∏–ª–∏ –Ω—ë–±–Ω–∞—è...\n",
       "4003  xml_corpus_4003        –ù–µ–±–æ –ù–µ–±–æ –ù–µ–±–æ (–ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –Ω–µ–±–µ—Å–∞, –Ω–µ–±–æ—Å–≤–æ–¥) ...\n",
       "4004  xml_corpus_4004        –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ ‚Äî —Å–æ...\n",
       "4005  xml_corpus_4005        –î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ –Ω–µ–±–∞ –î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ –Ω...\n",
       "4006  xml_corpus_4006                                              \" –ß–µ—Ä–Ω–æ–≤–∏–∫–∏\n",
       "\n",
       "[4007 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_corpus_file = extract_path / \"annot.opcorpora.xml\"\n",
    "tree = ET.parse(xml_corpus_file)\n",
    "root = tree.getroot()\n",
    "\n",
    "xml_texts = []\n",
    "for text_element in tqdm(root.findall('.//text')):\n",
    "    name_text = text_element.get('name', '')\n",
    "    source_texts = [source.text for source in text_element.findall('.//source') if source.text]\n",
    "\n",
    "    full_text_parts = [name_text] + source_texts\n",
    "    full_text = \" \".join(part.strip() for part in full_text_parts if part and part.strip())\n",
    "    \n",
    "    if full_text:\n",
    "        xml_texts.append(full_text)\n",
    "\n",
    "data_for_df = {\n",
    "    'item_id': [f'xml_corpus_{i}' for i in range(len(xml_texts))],\n",
    "    'title': '',\n",
    "    'description': xml_texts\n",
    "}\n",
    "additional_df = pd.DataFrame(data_for_df)\n",
    "additional_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0adce503",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([full_df, additional_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd3650",
   "metadata": {},
   "source": [
    "–í—Ä–æ–¥–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, —Ç–µ–ø–µ—Ä—å —Å–¥–µ–ª–∞–µ–º –∏–∑ —ç—Ç–æ–≥–æ –µ–¥–∏–Ω—ã–π –∫–æ—Ä–ø—É—Å —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96f90ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5aa8b125a3218ee10d56452d6e3fc6b05b92acae7e0710...</td>\n",
       "      <td>–ö–æc—Ç—é–º –∂–µ–Ωc–∫–∏–π</td>\n",
       "      <td>–ù–æ–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Ç</td>\n",
       "      <td>–ö–æc—Ç—é–º –∂–µ–Ωc–∫–∏–π. –ù–æ–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Ç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9f9b68e75034a161c116e764605db3275b514213c04ec7...</td>\n",
       "      <td>–®–∫–æ–ª—å–Ω—ã–π –∫–æc—Ç—é–º –¥–ª—è –ºa–ª—å—á–∏–∫a 134</td>\n",
       "      <td>–®–∫–æ–ª—å–Ω—ã–π –∫–æc—Ç—é–º –Ωa –ºa–ª—å—á–∏–∫a —á–µp–Ω–æ–≥–æ —Ü–≤–µ—Ça, pa–∑...</td>\n",
       "      <td>–®–∫–æ–ª—å–Ω—ã–π –∫–æc—Ç—é–º –¥–ª—è –ºa–ª—å—á–∏–∫a 134. –®–∫–æ–ª—å–Ω—ã–π –∫–æc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>538538e5282be1b3aa4cad2feb0000cadc9d4d6602b955...</td>\n",
       "      <td>–òc–ªa–ºc–∫a—è –∫ap—Ç–∏–Ωa –∏–∑ —ç–ø–æ–∫c–∏–¥–Ω–æ–π c–º–æ–ª—ã</td>\n",
       "      <td>–Ø p–∏c—É—é –∏c–ªa–ºc–∫–∏e –∫ap—Ç–∏–Ω—ã –∏–∑ —ç–ø–æ–∫c–∏–¥–Ω–æ–π c–ºo–ª—ã ...</td>\n",
       "      <td>–òc–ªa–ºc–∫a—è –∫ap—Ç–∏–Ωa –∏–∑ —ç–ø–æ–∫c–∏–¥–Ω–æ–π c–º–æ–ª—ã. –Ø p–∏c—É—é...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30f2136fc45172af7f66d4993132c05649c563c720dc52...</td>\n",
       "      <td>–ûp–∏–≥–∏–Ωa–ª Nike Air Jordan 1 High OG University ...</td>\n",
       "      <td>–ú—ã –∑a–∫–ª—é—á–∏–ª–∏ –¥–æ–≥–æ–≤–æp c –æ—Ñ–∏—Ü–∏a–ª—å–Ω—ã–º –¥–∏c—Çp–∏–±—å—é—Ç–æ...</td>\n",
       "      <td>–ûp–∏–≥–∏–Ωa–ª Nike Air Jordan 1 High OG University ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4afe50981f5dded76ad9c4357a1df34dcf28f6248e2ccf...</td>\n",
       "      <td>–öp–æcc–æ–≤–∫–∏ Nike Air Jordan 1 Low OG Travis Scot...</td>\n",
       "      <td>Nike Air Jordan 1 Low OG Travis Scott Black Ph...</td>\n",
       "      <td>–öp–æcc–æ–≤–∫–∏ Nike Air Jordan 1 Low OG Travis Scot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520493</th>\n",
       "      <td>xml_corpus_4002</td>\n",
       "      <td></td>\n",
       "      <td>–ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –∏–ª–∏ –Ω—ë–±–Ω–∞—è...</td>\n",
       "      <td>. –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –∏–ª–∏ –Ω—ë–±–Ω...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520494</th>\n",
       "      <td>xml_corpus_4003</td>\n",
       "      <td></td>\n",
       "      <td>–ù–µ–±–æ –ù–µ–±–æ –ù–µ–±–æ (–ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –Ω–µ–±–µ—Å–∞, –Ω–µ–±–æ—Å–≤–æ–¥) ...</td>\n",
       "      <td>. –ù–µ–±–æ –ù–µ–±–æ –ù–µ–±–æ (–ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –Ω–µ–±–µ—Å–∞, –Ω–µ–±–æ—Å–≤–æ–¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520495</th>\n",
       "      <td>xml_corpus_4004</td>\n",
       "      <td></td>\n",
       "      <td>–ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ ‚Äî —Å–æ...</td>\n",
       "      <td>. –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ ‚Äî ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520496</th>\n",
       "      <td>xml_corpus_4005</td>\n",
       "      <td></td>\n",
       "      <td>–î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ –Ω–µ–±–∞ –î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ –Ω...</td>\n",
       "      <td>. –î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ –Ω–µ–±–∞ –î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520497</th>\n",
       "      <td>xml_corpus_4006</td>\n",
       "      <td></td>\n",
       "      <td>\" –ß–µ—Ä–Ω–æ–≤–∏–∫–∏</td>\n",
       "      <td>. \" –ß–µ—Ä–Ω–æ–≤–∏–∫–∏</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2520498 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   item_id  \\\n",
       "0        5aa8b125a3218ee10d56452d6e3fc6b05b92acae7e0710...   \n",
       "1        9f9b68e75034a161c116e764605db3275b514213c04ec7...   \n",
       "2        538538e5282be1b3aa4cad2feb0000cadc9d4d6602b955...   \n",
       "3        30f2136fc45172af7f66d4993132c05649c563c720dc52...   \n",
       "4        4afe50981f5dded76ad9c4357a1df34dcf28f6248e2ccf...   \n",
       "...                                                    ...   \n",
       "2520493                                    xml_corpus_4002   \n",
       "2520494                                    xml_corpus_4003   \n",
       "2520495                                    xml_corpus_4004   \n",
       "2520496                                    xml_corpus_4005   \n",
       "2520497                                    xml_corpus_4006   \n",
       "\n",
       "                                                     title  \\\n",
       "0                                           –ö–æc—Ç—é–º –∂–µ–Ωc–∫–∏–π   \n",
       "1                         –®–∫–æ–ª—å–Ω—ã–π –∫–æc—Ç—é–º –¥–ª—è –ºa–ª—å—á–∏–∫a 134   \n",
       "2                    –òc–ªa–ºc–∫a—è –∫ap—Ç–∏–Ωa –∏–∑ —ç–ø–æ–∫c–∏–¥–Ω–æ–π c–º–æ–ª—ã   \n",
       "3        –ûp–∏–≥–∏–Ωa–ª Nike Air Jordan 1 High OG University ...   \n",
       "4        –öp–æcc–æ–≤–∫–∏ Nike Air Jordan 1 Low OG Travis Scot...   \n",
       "...                                                    ...   \n",
       "2520493                                                      \n",
       "2520494                                                      \n",
       "2520495                                                      \n",
       "2520496                                                      \n",
       "2520497                                                      \n",
       "\n",
       "                                               description  \\\n",
       "0                                           –ù–æ–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Ç   \n",
       "1        –®–∫–æ–ª—å–Ω—ã–π –∫–æc—Ç—é–º –Ωa –ºa–ª—å—á–∏–∫a —á–µp–Ω–æ–≥–æ —Ü–≤–µ—Ça, pa–∑...   \n",
       "2        –Ø p–∏c—É—é –∏c–ªa–ºc–∫–∏e –∫ap—Ç–∏–Ω—ã –∏–∑ —ç–ø–æ–∫c–∏–¥–Ω–æ–π c–ºo–ª—ã ...   \n",
       "3        –ú—ã –∑a–∫–ª—é—á–∏–ª–∏ –¥–æ–≥–æ–≤–æp c –æ—Ñ–∏—Ü–∏a–ª—å–Ω—ã–º –¥–∏c—Çp–∏–±—å—é—Ç–æ...   \n",
       "4        Nike Air Jordan 1 Low OG Travis Scott Black Ph...   \n",
       "...                                                    ...   \n",
       "2520493  –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –∏–ª–∏ –Ω—ë–±–Ω–∞—è...   \n",
       "2520494  –ù–µ–±–æ –ù–µ–±–æ –ù–µ–±–æ (–ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –Ω–µ–±–µ—Å–∞, –Ω–µ–±–æ—Å–≤–æ–¥) ...   \n",
       "2520495  –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ ‚Äî —Å–æ...   \n",
       "2520496  –î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ –Ω–µ–±–∞ –î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ –Ω...   \n",
       "2520497                                        \" –ß–µ—Ä–Ω–æ–≤–∏–∫–∏   \n",
       "\n",
       "                                                      text  \n",
       "0                           –ö–æc—Ç—é–º –∂–µ–Ωc–∫–∏–π. –ù–æ–≤—ã–π –∫–æ–º–ø–ª–µ–∫—Ç  \n",
       "1        –®–∫–æ–ª—å–Ω—ã–π –∫–æc—Ç—é–º –¥–ª—è –ºa–ª—å—á–∏–∫a 134. –®–∫–æ–ª—å–Ω—ã–π –∫–æc...  \n",
       "2        –òc–ªa–ºc–∫a—è –∫ap—Ç–∏–Ωa –∏–∑ —ç–ø–æ–∫c–∏–¥–Ω–æ–π c–º–æ–ª—ã. –Ø p–∏c—É—é...  \n",
       "3        –ûp–∏–≥–∏–Ωa–ª Nike Air Jordan 1 High OG University ...  \n",
       "4        –öp–æcc–æ–≤–∫–∏ Nike Air Jordan 1 Low OG Travis Scot...  \n",
       "...                                                    ...  \n",
       "2520493  . –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –ú—è–≥–∫–æ–µ –Ω—ë–±–æ –∏–ª–∏ –Ω—ë–±–Ω...  \n",
       "2520494  . –ù–µ–±–æ –ù–µ–±–æ –ù–µ–±–æ (–ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –Ω–µ–±–µ—Å–∞, –Ω–µ–±–æ—Å–≤–æ–¥...  \n",
       "2520495  . –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ –ó–≤—ë–∑–¥–Ω–æ–µ –Ω–µ–±–æ ‚Äî ...  \n",
       "2520496  . –î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ –Ω–µ–±–∞ –î–∏—Ñ—Ñ—É–∑–Ω–æ–µ –∏–∑–ª—É—á–µ–Ω–∏–µ...  \n",
       "2520497                                      . \" –ß–µ—Ä–Ω–æ–≤–∏–∫–∏  \n",
       "\n",
       "[2520498 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[\"text\"] = full_df[\"title\"] + \". \" + full_df[\"description\"]\n",
    "full_df.drop([\"title\", \"description\"], axis=1)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05dbda55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cb80cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2520498/2520498 [01:13<00:00, 34417.99it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2520498/2520498 [01:05<00:00, 38725.92it/s]\n"
     ]
    }
   ],
   "source": [
    "text = full_df[\"text\"].tolist()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "def preprocess(line):\n",
    "\tline = line.lower().replace(\"—ë\", \"–µ\")\n",
    "\tline = re.sub(r\"\\s+\", \" \", line).strip()\n",
    "\treturn line\n",
    "\n",
    "\n",
    "for line in tqdm(text):\n",
    "\tcleaned_line = preprocess(line)\n",
    "\tif len(cleaned_line):\n",
    "\t\tcorpus.append(cleaned_line)\n",
    "\n",
    "with open(\"clean_corpus.txt\", \"w\", encoding=\"utf8\") as file:\n",
    "\tfor line in tqdm(corpus):\n",
    "\t\tfile.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52403c",
   "metadata": {},
   "source": [
    "–ü–æ—Å–∫–æ–ª—å–∫—É –¥–∞—Ç–∞—Å–µ—Ç –±—ã–ª –¥–ª—è —Ä–∞–∑–ª–∏—á–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –æ–±—ä—è–≤–ª–µ–Ω–∏–π, –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –æ–ø–∏—Å–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è —á–∞—â–µ, —á–µ–º —Å–ª–µ–¥—É–µ—Ç, –Ω–æ —Å–∏–ª—å–Ω–æ —ç—Ç–æ –Ω–µ –¥–æ–ª–∂–Ω–æ –ø–æ–º–µ—à–∞—Ç—å. (–Ω–æ –≤–æ–æ–±—â–µ –º—É—Å–æ—Ä–∞ –º–Ω–æ–≥–æ–≤–∞—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å, –Ω–∞ –∏—Ç–æ–≥–æ–≤–æ–º –∫–∞—á–µ—Å—Ç–≤–µ —ç—Ç–æ –º–æ–∂–µ—Ç —Å–∫–∞–∑–∞—Ç—å—Å—è)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edcf93",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ–π–¥–µ–º –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –∫ –º–æ–¥–µ–ª–∏. –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ, –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —É–Ω–∏–≥—Ä–∞–º–º–∞–º –∏ –±–∏–≥—Ä–∞–º–º–∞–º –≤ –∫–æ—Ä–ø—É—Å–µ, –Ω—É–∂–Ω–æ –∏—Ö –ø–æ—Å—á–∏—Ç–∞—Ç—å, –∞ –ø–æ—Ç–æ–º –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–æ—Ä–º—É–ª—ã:\n",
    "\n",
    "$$\n",
    "\tp(\\text{word}_2 | \\text{word}_1) = \\frac{p(\\text{word}_1, \\text{word}_2)}{p(\\text{word}_1)}\n",
    "$$\n",
    "\n",
    "–≥–¥–µ\n",
    "\n",
    "$$\n",
    "p(\\text{word}_i) = \\frac{n_{\\text{word}_i}}{n}, \\quad p(\\text{word}_i, \\text{word}_{i-1}) = \\frac{n_{\\text{word}_i, \\text{word}_{i-1}}}{n}\n",
    "$$\n",
    "\n",
    "—Ç–æ–≥–¥–∞ —é–∑–∞–±–µ–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞:\n",
    "\n",
    "$$\n",
    "p(\\text{word}_i | \\text{word}_{i-1}) = \\frac{n_{\\text{word}_i, \\text{word}_{i-1}}}{n_{\\text{word}_{i-1}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13beb13",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ–π–¥–µ–º –∫ –ø–æ–¥—Å—á–µ—Ç–∞–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6acb8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3494545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2520498it [49:43, 844.80it/s]                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: 867914283\n",
      "—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 2205919\n",
      "—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±–∏–≥—Ä–∞–º–º: 14557985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unigram_counts = defaultdict(int)\n",
    "bigram_counts = defaultdict(int)\n",
    "total_words = 0\n",
    "\n",
    "with open(\"clean_corpus.txt\", \"r\", encoding='utf8') as file:\n",
    "    for line in tqdm(file, total=2_500_000):\n",
    "        tokens = [token.text for token in tokenize(line)]\n",
    "        \n",
    "        if not tokens:\n",
    "            continue\n",
    "            \n",
    "        total_words += len(tokens)\n",
    "        \n",
    "        for word in tokens:\n",
    "            unigram_counts[word] += 1\n",
    "\n",
    "        for i in range(len(tokens) - 1):\n",
    "            bigram = (tokens[i], tokens[i+1])\n",
    "            bigram_counts[bigram] += 1\n",
    "\n",
    "print(f\"–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤: {total_words}\")\n",
    "print(f\"—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(unigram_counts)}\")\n",
    "print(f\"—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±–∏–≥—Ä–∞–º–º: {len(bigram_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476e950",
   "metadata": {},
   "source": [
    "*–ö–∞–∫-—Ç–æ –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ —Å —ç—Ç–∏–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º –≤—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç. –¢–∞–∫–æ–µ –æ—â—É—â–µ–Ω–∏–µ, —á—Ç–æ –≤—Ä—É—á–Ω—É—é –Ω–∞–ø–∏—Å–∞—Ç—å –∫–æ–¥ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ —Ç–æ–∫–µ–Ω—ã –±—ã–ª–æ –±—ã –±—ã—Å—Ç—Ä–µ–µ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "512ead5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 189 0 2\n"
     ]
    }
   ],
   "source": [
    "print(unigram_counts[\"–≤–∏–≤–æ\"], unigram_counts[\"—Å—è–æ–º–∏\"], unigram_counts[\"–∫—Å—è–æ–º–∏\"], unigram_counts[\"–∫—Å–∏–æ–º–∏\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d06b623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13\n",
      "152 1\n"
     ]
    }
   ],
   "source": [
    "print(bigram_counts[(\"—Å–º–∞—Ä—Ç—Ñ–æ–Ω\", \"vivo\")], bigram_counts[(\"—Ç–µ–ª–µ—Ñ–æ–Ω\", \"vivo\")])\n",
    "print(bigram_counts[(\"—Ö–æ—Ä–æ—à–µ–º\", \"—Å–æ—Å—Ç–æ—è–Ω–∏–∏\")], bigram_counts[(\"–ø–ª–æ—Ö–æ–º\", \"—Å–æ—Å—Ç–æ—è–Ω–∏–∏\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f52f57",
   "metadata": {},
   "source": [
    "–í–∏–¥–Ω–æ, —á—Ç–æ –¥–∞—Ç–∞—Å–µ—Ç –¥–æ–≤–æ–ª—å–Ω–æ –º–∞–ª–µ–Ω—å–∫–∏–π, —á—Ç–æ–±—ã —Å —Ö–æ—Ä–æ—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É. –°–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ —Ç–æ—á–Ω–æ –¥–æ–ª–∂–Ω—ã –≤—Å—Ç—Ä–µ—á–∞—Ç—å—Å—è —Å—Ä–µ–¥–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤–º–µ—Å—Ç–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä \"—Å–º–∞—Ä—Ç—Ñ–æ–Ω vivo\", –≤ –¥–∞—Ç–∞—Å–µ—Ç –Ω–µ –≤—Ö–æ–¥—è—Ç, —Ç–∞–∫ —á—Ç–æ $p(\\text{\"—Å–º–∞—Ä—Ç—Ñ–æ–Ω\"} | \\text{\"vivo\"})$ –±—É–¥–µ—Ç —Å—Ç—Ä–æ–≥–∏–º –Ω—É–ª–µ–º –≤–º–µ—Å—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä–æ–≥–æ –º–∞–ª–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e5d6c",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –Ω—É–∂–Ω–æ –ø—Ä–∏–¥—É–º–∞—Ç—å, –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø–æ–ª—É—á–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ. –î–ª—è —Å—Ç—Ä–æ–∫–∏ –¥–ª–∏–Ω—ã $l$ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–±–∏–µ–Ω–∏–π –∑–∞–≤–∏—Å–∏—Ç –æ—Ç $l$ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ, —Ç–∞–∫ —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–±–æ—Ä –≤—Å–µ—Ö –º–æ–∂–µ—Ç –æ–∫–∞–∑–∞—Ç—å—Å—è —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–∏–º. –ù—É–∂–Ω–æ –ø—Ä–∏–¥—É–º–∞—Ç—å –Ω–µ—á—Ç–æ –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ, –∏—Å–ø–æ–ª—å–∑—É—è –ø–æ–¥—Ö–æ–¥ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffa39c",
   "metadata": {},
   "source": [
    "–†–µ—à–µ–Ω–∏–µ:\n",
    "\n",
    "* –ü—É—Å—Ç—å –º—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –∏–∑ $i$ –ø–µ—Ä–≤—ã—Ö –±—É–∫–≤. –¢–æ–≥–¥–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª—É—á—à–µ–≥–æ –µ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è –±—É–¥–µ–º —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –≤—Å–µ –µ–≥–æ —Å—É—Ñ—Ñ–∏–∫—Å—ã (–±—É–∫–≤—ã –æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä–æ–≥–æ $j$ –¥–æ $i$) –∏ —Å—á–∏—Ç–∞—Ç—å —Å–∫–æ—Ä —Ä–∞–∑–±–∏–µ–Ω–∏—è —Å –ø–æ—Å–ª–µ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º $[j:i]$. –î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å —Å–∫–æ—Ä –ª—É—á—à–µ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è –ø—Ä–µ—Ñ–∏–∫—Å–∞ $[:j]$ –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞ $[j:i]$ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ–≤–∞ –∏–∑ –ª—É—á—à–µ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è –ø—Ä–µ—Ñ–∏–∫—Å–∞ $[:j]$. –î–∞–ª–µ–µ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –≤—ã–±—Ä–∞—Ç—å –ª—É—á—à–µ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ —Å–∫–æ—Ä—É –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –µ–≥–æ.\n",
    "\n",
    "* –ü—Ä–∏ —ç—Ç–æ–º, —Å–∫–æ—Ä —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—Ç—Å—è, –∫–∞–∫\n",
    "$$\n",
    "score(x) := \\log p(x) = \\log p(x_1) + \\sum \\log p(x_i | x_{i-1})\n",
    "$$\n",
    "\n",
    "* –î–∞–ª–µ–µ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Å–∏–º–≤–æ–ª—É –∏ —Ç–∞–∫ –∂–µ –ø–µ—Ä–µ–±–∏—Ä–∞–µ–º —Ä–∞–∑–±–∏–µ–Ω–∏—è –ø—Ä–µ—Ñ–∏–∫—Å–∞.\n",
    "\n",
    "* –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —É –Ω–∞—Å –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Ç–∞–±–ª–∏—Ü–∞ —Å–æ —Å–∫–æ—Ä–∞–º–∏ –ª—É—á—à–µ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è –≤—Å–µ—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ —Å—Ç—Ä–æ–∫–∏ –∏ —Å –ø–æ–º–æ—â—å—é –Ω–µ–µ –º—ã —Å–º–æ–∂–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —ç—Ç–æ —Ä–∞–∑–±–∏–µ–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6a69bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = {\n",
    "    \"unigram_counts\": dict(unigram_counts),\n",
    "    \"bigram_counts\": dict(bigram_counts),\n",
    "    \"total_words\": total_words,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "b12ab4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_bonus(word_len):\n",
    "    return (word_len - 1) ** 2 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "02aea966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splitter:\n",
    "\tdef __init__(self, model_data=model_data):\n",
    "\t\tself.unigrams = model_data[\"unigram_counts\"]\n",
    "\t\tself.bigrams = model_data[\"bigram_counts\"]\n",
    "\t\tself.total = model_data[\"total_words\"]\n",
    "\t\tself.log_total = np.log10(self.total)\n",
    "\t\tself.vocabular = set(self.unigrams.keys())\n",
    "\n",
    "\tdef unigram_score(self, word):\n",
    "\t\tcount = self.unigrams.get(word, 0)\n",
    "\t\tif count == 0:\n",
    "\t\t\treturn -np.inf\n",
    "\t\treturn np.log10(count) - self.log_total\n",
    "\n",
    "\tdef bigram_score(self, word_1, word_2):\n",
    "\t\tbigram_count = self.bigrams.get((word_1, word_2), 0)\n",
    "\t\tword1_count = self.unigrams.get(word_1, 0)\n",
    "\n",
    "\t\t#  –µ—Å–ª–∏ –±–∏–≥—Ä–∞–º–º—ã –Ω–µ—Ç, —Å—á–∏—Ç–∞–µ–º —Å–ª–æ–≤–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–º–∏, —Ç–æ–≥–¥–∞ —Å–∫–æ—Ä –ø–∞—Ä—ã - —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —Å—É–º–º–∞ —Å–∫–æ—Ä–æ–≤\n",
    "\t\tif bigram_count > 0 and word1_count > 0:\n",
    "\t\t\treturn np.log10(bigram_count) - np.log10(word1_count)\n",
    "\t\telse:\n",
    "\t\t\treturn self.unigram_score(word_1) + self.unigram_score(word_2)\n",
    "\n",
    "\tdef split(self, text):\n",
    "\t\tmem = {0: (0., 0)}\n",
    "\n",
    "\t\tfor i in range(1, len(text) + 1):\n",
    "\t\t\tbest_score = -np.inf\n",
    "\t\t\tbest_split_pos = 0\n",
    "\n",
    "\t\t\tfor j in range(max(0, i-20), i):\n",
    "\t\t\t\tword = text[j:i]\n",
    "\n",
    "\t\t\t\tif word in self.vocabular:\n",
    "\t\t\t\t\tprev_score, prev_best_split_pos = mem.get(j, (-np.inf, 0))\n",
    "\t\t\t\t\tif prev_score == -np.inf:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tprev_word = text[mem[j][1]:j] if j > 0 else None\n",
    "\n",
    "\t\t\t\t\tlog_prob = self.unigram_score(word) if prev_word is None else self.bigram_score(prev_word, word)\n",
    "\n",
    "\t\t\t\t\tnew_score = prev_score + log_prob + len_bonus(len(word))\n",
    "\n",
    "\t\t\t\t\tif new_score > best_score:\n",
    "\t\t\t\t\t\tbest_score = new_score\n",
    "\t\t\t\t\t\tbest_split_pos = j\n",
    "\n",
    "\t\t\tmem[i] = (best_score, best_split_pos)\n",
    "\n",
    "\t\tif mem[len(text)][0] == -np.inf:\n",
    "\t\t\treturn text\n",
    "\t\telse:\n",
    "\t\t\tresult = []\n",
    "\t\t\ti = len(text)\n",
    "\t\t\twhile i != 0:\n",
    "\t\t\t\tj = mem[i][1]\n",
    "\t\t\t\tresult.append(text[j:i])\n",
    "\t\t\t\ti = j\n",
    "\n",
    "\t\t\tresult.reverse()\n",
    "\t\t\treturn \" \".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "c1e27894",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = Splitter(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "6969b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–∞–π—Ñ–æ–Ω 16 –ø—Ä–æ–º–∞—Ö\n",
      "–∞–π—Ñ–æ–Ω 16 –ø—Ä–æ –º–∞–∫—Å\n",
      "–∞–π—Ñ–æ–Ω 1 8 –ø—Ä–æ –º–∞–∫—Å\n",
      "–ø—Ä–æ–¥–∞–º –∫–æ–ª–µ—Å–æ –Ω–µ–¥–æ—Ä–æ–≥–æ\n"
     ]
    }
   ],
   "source": [
    "print(splitter.split(\"–∞–π—Ñ–æ–Ω16–ø—Ä–æ–º–∞—Ö\"))\n",
    "print(splitter.split(\"–∞–π—Ñ–æ–Ω16–ø—Ä–æ–º–∞–∫—Å\"))\n",
    "print(splitter.split(\"–∞–π—Ñ–æ–Ω18–ø—Ä–æ–º–∞–∫—Å\"))\n",
    "print(splitter.split(\"–ø—Ä–æ–¥–∞–º–∫–æ–ª–µ—Å–æ–Ω–µ–¥–æ—Ä–æ–≥–æ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b1a084",
   "metadata": {},
   "source": [
    "–í—ã–≥–ª—è–¥–∏—Ç –Ω–µ–ø–ª–æ—Ö–æ. –í–µ—Å–æ–≤ –Ω–µ–º–∞–ª–æ -- –º–æ–¥–µ–ª—å –Ω–∞ 700–ú–ë, –∑–∞—Ç–æ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –±–µ–∑ –≥–ø—É –±–µ–∑ –ø—Ä–æ–±–ª–µ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "291845d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_path = Path('bigram_model.pkl')\n",
    "with model_path.open('wb') as f:\n",
    "\tpickle.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c6969",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—Å–µ –≥–æ—Ç–æ–≤–æ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "ecb3ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_map(text):\n",
    "    clean_chars = []\n",
    "    clean_to_original_map = []\n",
    "\n",
    "    for i, char in enumerate(text):\n",
    "        if not char.isspace():\n",
    "            clean_chars.append(char)\n",
    "            clean_to_original_map.append(i)\n",
    "\n",
    "    clean_text_for_splitter = \"\".join(clean_chars).lower().replace('—ë', '–µ')\n",
    "\n",
    "    return clean_text_for_splitter, clean_to_original_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "db43faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_punctuation(text):\n",
    "\ttext = re.sub(r'\\s([?.!,:;\")])', r'\\1', text)\n",
    "\t\n",
    "\ttext = re.sub(r'([(\"])\\s', r'\\1', text)\n",
    "\n",
    "\ttext = re.sub(r'(\\S)-\\s', r'\\1 - ', text)\n",
    "\ttext = re.sub(r'\\s-(\\S)', r' - \\1', text)\n",
    "\t\n",
    "\treturn text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "34c4479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce9558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1005/1005 [00:00<00:00, 3239.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     text_no_spaces                        predicted_text\n",
      "14          –∏—â—É—Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä–∞–ø–æ–±–∏–æ–ª–æ–≥–∏–∏            –∏—â—É —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä–∞ –ø –æ–±–∏–æ–ª–æ–≥–∏–∏\n",
      "64           –∫—É–ø–ª—é—Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫Atlant              –∫—É–ø–ª—é —Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫ atlant\n",
      "128      —Å–¥–∞–º–ø–∞—Ä–∫–æ–≤–∫—É–≤—Ü–µ–Ω—Ç—Ä–µ,–æ—Ö—Ä–∞–Ω–∞        —Å–¥–∞–º –ø–∞—Ä–∫–æ–≤–∫—É –≤ —Ü–µ–Ω—Ç—Ä–µ, –æ—Ö—Ä–∞–Ω–∞\n",
      "343              –ú–æ—Å–∫–≤–∞Ikea–¥–æ—Å—Ç–∞–≤–∫–∞                  –º–æ—Å–∫–≤–∞ ikea –¥–æ—Å—Ç–∞–≤–∫–∞\n",
      "471           –Ø–¥–∞–≤–ª—é—Å—å,–∏–∑—Ä—ã–≥–∞—è–æ–≥–æ–Ω—å           —è –¥–∞–≤–ª—é —Å—å, –∏–∑ —Ä—ã –≥–∞ —è–æ–≥–æ–Ω—å\n",
      "520            –•–æ—á–µ—à—å–∑–∞–æ–∫–æ—à–∫–æ–º–ê–ª—å–ø—ã              —Ö–æ—á–µ—à—å –∑ –∞ –æ–∫–æ—à–∫–æ–º –∞–ª—å–ø—ã\n",
      "647   –ß—Ç–æ–±—ã–±—ã–ª–∏–¥—Ä—É–∑—å—è–∏–ª–∏,—Ö–æ—Ç—è–±—ã–æ–¥–∏–Ω    —á—Ç–æ–±—ã –±—ã–ª–∏ –¥—Ä—É–∑—å—è –∏–ª–∏, —Ö–æ—Ç—è–±—ã –æ–¥–∏–Ω\n",
      "812   –ì–æ–¥—ã–ø—Ä–æ—à–ª–∏,–ì–æ—Ä–æ–¥–µ—Ü–∫–∏–π–Ω–µ—Ç—É–∂–∏—Ç,   –≥–æ–¥—ã –ø—Ä–æ—à–ª–∏, –≥–æ—Ä–æ–¥ –µ—Ü–∫–∏–π –Ω –µ —Ç—É–∂–∏—Ç,\n",
      "838       –ö–∞–∫–∏–µ-—Ç–æ–ª—é–¥–∏—Ç–µ–±—è–æ–∫—Ä—É–∂–∞—é—Ç,          –∫–∞–∫–∏–µ-—Ç–æ –ª—é–¥–∏ —Ç–µ–±—è –æ–∫—Ä—É–∂–∞—é—Ç,\n",
      "856  –ò–≤–¥–æ–º–µ–ª–µ—Å–Ω–∏–∫–∞—è–Ω–æ—á–ª–µ–≥–∞–ø–æ–ø—Ä–æ—Å–∏–ª.  –∏ –≤–¥–æ–º–µ –ª–µ—Å–Ω–∏–∫–∞ —è –Ω–æ—á–ª–µ–≥ –∞ –ø–æ–ø—Ä–æ—Å–∏–ª.\n",
      "      id      predicted_positions\n",
      "14    14              [3, 13, 14]\n",
      "64    64                  [5, 16]\n",
      "128  128          [4, 12, 13, 20]\n",
      "343  343                  [6, 10]\n",
      "471  471    [1, 6, 9, 11, 13, 15]\n",
      "520  520            [6, 7, 8, 15]\n",
      "647  647       [5, 9, 15, 19, 25]\n",
      "812  812  [4, 11, 16, 21, 22, 23]\n",
      "838  838              [8, 12, 16]\n",
      "856  856   [1, 6, 13, 14, 20, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "task_data = pd.read_csv(\"dataset.txt\", sep=\";\", engine=\"python\")\n",
    "\n",
    "all_predicted_positions = []\n",
    "all_predicted_texts = []\n",
    "\n",
    "for text_no_spaces in tqdm(task_data['text_no_spaces']):\n",
    "\tclean_text, mapping = preprocess_and_map(text_no_spaces)\n",
    "\t\n",
    "\tif not clean_text:\n",
    "\t\tall_predicted_texts.append(text_no_spaces)\n",
    "\t\tcontinue\n",
    "\n",
    "\traw_split_text = splitter.split(clean_text)\n",
    "\n",
    "\tfinal_split_text = post_process_punctuation(raw_split_text)\n",
    "\tall_predicted_texts.append(final_split_text)\n",
    "\n",
    "\ttokens = final_split_text.split(' ')\n",
    "\t\n",
    "\tlengths = [len(token) for token in tokens[:-1]]\n",
    "    \n",
    "\tpositions = list(map(str, itertools.accumulate(lengths)))\n",
    "\n",
    "\tpositions_str = \"[\" + \", \".join(positions) + \"]\"\n",
    "\tall_predicted_positions.append(positions_str)\n",
    "\n",
    "\n",
    "submission_df = task_data.copy()\n",
    "submission_df[\"predicted_text\"] = all_predicted_texts\n",
    "submission_df[\"predicted_positions\"] = all_predicted_positions\n",
    "answers_df = submission_df[[\"id\", \"predicted_positions\"]].copy()\n",
    "\n",
    "idxs = np.random.randint(0, 1000, 10)\n",
    "print(submission_df[[\"text_no_spaces\", \"predicted_text\"]][submission_df[\"id\"].isin(idxs)])\n",
    "print(answers_df[submission_df[\"id\"].isin(idxs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df93bb",
   "metadata": {},
   "source": [
    "*–ö–∞–∫ –¥–ª—è –º–æ–¥–µ–ª–∏ –Ω–∞ –±–∏–≥—Ä–∞–º–º–∞—Ö, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –≥–ø—É –∏ —á–µ–≥–æ-—Ç–æ —Å–ª–æ–∂–Ω–æ–≥–æ, –ø–æ–ª—É—á–∏–ª–æ—Å—å –Ω–µ–ø–ª–æ—Ö–æ, –Ω–æ –æ—Ç –∏–¥–µ–∞–ª–∞ –æ—á–µ–Ω—å –¥–∞–ª–µ–∫–æ. –°–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –¥–∞—Ç–∞—Å–µ—Ç–∞, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å. –î–æ–≤–æ–ª—å–Ω–æ —á–∞—Å—Ç–æ –º–æ–∂–Ω–æ –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞, –ø—Ä–∏ —ç—Ç–æ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö —Å–ª–æ–≤, —Ä–µ–¥–∫–∏—Ö, –∑–∞—á–∞—Å—Ç—É—é –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è. –î–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞, –∏ —Ç–µ–º –±–æ–ª–µ–µ, –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç—Ä–∏–≥—Ä–∞–º–º —Å–ª–µ–¥—É–µ—Ç –Ω–∞–π—Ç–∏ –±–æ–ª–µ–µ –æ–±—à–∏—Ä–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç.*\n",
    "\n",
    "*–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–∂–µ —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –ø–æ–¥–∞–≤–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å –¥–æ–ª–≥–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∏ —Å —Ö–æ—Ä–æ—à–∏–º —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–æ–º. –í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —Ç–æ–∫–µ–Ω—ã –±—É–¥–µ—Ç —É–∂–µ –±–æ–ª–µ–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–º –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —Ç–æ–∫–µ–Ω—ã —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤. –û–¥–Ω–∞–∫–æ, —Ç–æ–≥–¥–∞ –ø–æ—Ç–µ—Ä—è–µ—Ç—Å—è —Å–º—ã—Å–ª —Ç–∞–∫–æ–π –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏, –Ω–∞ –±–∏–≥—Ä–∞–º–º–∞—Ö, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∏ –Ω–∏–∑–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ —É—Å—Ç—Ä–æ–π—Å—Ç–≤—É, –∞ –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏, –∫–∞–∂–µ—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–æ —Å–ª–æ–∂–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π –∏–∑–ª–∏—à–Ω–µ. –° —Ç–∞–∫–∏–º –∂–µ —É—Å–ø–µ—Ö–æ–º –º–æ–∂–Ω–æ —Å–∫–æ—Ä–º–∏—Ç—å —Å–ª–∏—Ç–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –≥–ø—Ç —Å –ø—Ä–æ–º–ø—Ç–æ–º –∏ –æ–Ω–∞ –∏—Ö –æ—Ç–ª–∏—á–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç. –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–Ω–æ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—å –∑–∞ —Å—á–µ—Ç –±–æ–ª–µ–µ —Ç—â–∞—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞ –∏ –æ—á–∏—Å—Ç–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç—Ä–µ—Ö–≥—Ä–∞–º–º. –•–æ—Ç—è –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ, –Ω–æ –≤—Å–µ –µ—â–µ –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –º–æ–≥—É—Ç –ø–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ª—É—á—à–µ.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "b879f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_df.to_csv(\"answers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b6ab7",
   "metadata": {},
   "source": [
    "92% f1 score, –Ω–µ –≥—É—Å—Ç–æ. –ù–∞–¥–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —É–ª—É—á—à–∏—Ç—å —ç—Ç–æ.\n",
    "\n",
    "–•–æ—Ä–æ—à–∏–π –¥–∞—Ç–∞—Å–µ—Ç, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è –¥–∞–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏, –µ—â–µ –∏ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–±—É—á–µ–Ω–∏–µ –Ω–µ –∑–∞–Ω–∏–º–∞–ª–æ –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏, –Ω–∞–π—Ç–∏ —Å–ª–æ–∂–Ω–æ. –¢–∞–∫ —á—Ç–æ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å. –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∏–∫—Ä–æ–±–µ—Ä—Ç –Ω–∞ 12–ú –≤–µ—Å–æ–≤, –æ–±—É—á–µ–Ω–Ω—ã–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ–º, –∞ –∏–º–µ–Ω–Ω–æ https://huggingface.co/DeepPavlov/distilrubert-tiny-cased-conversational-v1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "dfaad608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.56.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hxrt mx\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "66ab3414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a495b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyBertCorrector(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.bert = AutoModel.from_pretrained(\"DeepPavlov/distilrubert-tiny-cased-conversational-v1\")\n",
    "\n",
    "\t\tfor param in self.bert.parameters():\n",
    "\t\t\tparam.require_grad = False\n",
    "\n",
    "\t\tself.hiddend_size = 264\n",
    "\t\tself.classifier = nn.Sequential(\n",
    "\t\t\tnn.Linear(self.hiddend_size, 256),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(0.2),\n",
    "\t\t\tnn.Linear(256, 1),\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, tensor):\n",
    "\t\treturn self.classifier(self.bert(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "a1c8c0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\hxrt mx\\.cache\\huggingface\\hub\\models--DeepPavlov--distilrubert-tiny-cased-conversational-v1\\snapshots\\2033d0d1de807e8181ebfa0e53d2a8e526412b0f\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 264,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 792,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"transformers_version\": \"4.56.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\hxrt mx\\.cache\\huggingface\\hub\\models--DeepPavlov--distilrubert-tiny-cased-conversational-v1\\snapshots\\2033d0d1de807e8181ebfa0e53d2a8e526412b0f\\vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\hxrt mx\\.cache\\huggingface\\hub\\models--DeepPavlov--distilrubert-tiny-cased-conversational-v1\\snapshots\\2033d0d1de807e8181ebfa0e53d2a8e526412b0f\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\hxrt mx\\.cache\\huggingface\\hub\\models--DeepPavlov--distilrubert-tiny-cased-conversational-v1\\snapshots\\2033d0d1de807e8181ebfa0e53d2a8e526412b0f\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\hxrt mx\\.cache\\huggingface\\hub\\models--DeepPavlov--distilrubert-tiny-cased-conversational-v1\\snapshots\\2033d0d1de807e8181ebfa0e53d2a8e526412b0f\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 264,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 792,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"transformers_version\": \"4.56.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\hxrt mx\\.cache\\huggingface\\hub\\models--DeepPavlov--distilrubert-tiny-cased-conversational-v1\\snapshots\\2033d0d1de807e8181ebfa0e53d2a8e526412b0f\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 264,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 792,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"transformers_version\": \"4.56.2\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/distilrubert-tiny-cased-conversational-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6e4a1d",
   "metadata": {},
   "source": [
    "–î–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –Ω–∞—à–µ–º –∫–æ—Ä–ø—É—Å–µ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è —Å–¥–µ–ª–∞—Ç—å –∏–∑ –Ω–µ–≥–æ –Ω–∞–±–æ—Ä —Ç–æ–∫–µ–Ω–æ–≤ —Å –º–µ—Ç–∫–∞–º–∏, —Å—Ç–∞–≤–∏—Ç—å—Å—è –ª–∏ –ø—Ä–æ–±–µ–ª –º–µ–∂–¥—É –Ω–∏–º–∏, –∏–ª–∏ –Ω–µ—Ç. –î–ª—è —ç—Ç–æ–≥–æ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∫–æ—Ä–ø—É—Å -- open corpora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f5a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñã        | 655/4007 [00:14<00:22, 150.78it/s]"
     ]
    }
   ],
   "source": [
    "corpus = additional_df[\"description\"].tolist()\n",
    "\n",
    "correct_tokens = []\n",
    "bigram_model_out_tokens = []\n",
    "\n",
    "for text in tqdm(corpus):\n",
    "\tpreprocess_text = preprocess(text)\n",
    "\tbigram_model_out = splitter.split(preprocess_text)\n",
    "\t\n",
    "\tbigram_model_out_tokens.append(tokenizer.tokenize(bigram_model_out))\n",
    "\tcorrect_tokens.append(tokenizer.tokenize(preprocess_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "d191bab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram_model out tokens: ['\"', '—á–∞—Å—Ç–Ω—ã–π', '–∫–æ—Ä—Ä–µ—Å–ø–æ–Ω', '##–¥–µ–Ω—Ç', '\"']\n",
      "correct tokens: ['\"', '–ß–∞', '##—Å—Ç–Ω—ã–π', '–∫–æ—Ä—Ä–µ—Å–ø–æ–Ω', '##–¥–µ–Ω—Ç', '\"']\n"
     ]
    }
   ],
   "source": [
    "print(f\"bigram_model out tokens: {bigram_model_out_tokens[0]}\")\n",
    "print(f\"correct tokens: {correct_tokens[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113dc02a",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –Ω—É–∂–Ω–æ –Ω–∞—É—á–∏—Ç—å –Ω–∞—à –º–∏–∫—Ä–æ–±–µ—Ä—Ç —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º –Ω–∞ –≥–æ–ª–æ–≤–µ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã —Å–æ—Å–µ–¥–Ω–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å: –¥–æ–ª–∂–µ–Ω —Ç–∞–º —Å—Ç–æ—è—Ç—å –ø—Ä–æ–±–µ–ª, –∏–ª–∏ –Ω–µ—Ç."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
